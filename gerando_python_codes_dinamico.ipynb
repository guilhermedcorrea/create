{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, OrderedDict\n",
    "from pyspark.sql.types import StructType, StructField, StringType, LongType, IntegerType, TimestampType, DoubleType\n",
    "import csv\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nome da Tabela: ft_alerta_operacao_horario_celular_diferente\n",
      "\n",
      "Critério de Agrupamento: ft_alerta_operacao_horario_celular_diferente, Contagem de Colunas: 9\n",
      "Colunas:\n",
      "StructType([\n",
      "StructField('id_ft_alerta_operacao',LongType(), True), \\\n",
      "StructField('id_url',StringType(), True), \\\n",
      "StructField('id_dim_ambiente',LongType(), True), \\\n",
      "StructField('id_dim_colaborador',LongType(), True), \\\n",
      "StructField('status',IntegerType(), True), \\\n",
      "StructField('detalhe_alerta_operacao',StringType(), True), \\\n",
      "StructField('modelo_celular',StringType(), True), \\\n",
      "StructField('horario_celular',TimestampType(), True), \\\n",
      "StructField('horario_atomico',TimestampType(), True)])\n",
      "\n",
      "Nome da Tabela: ft_alerta_operacao_nivel_bateria\n",
      "\n",
      "Critério de Agrupamento: ft_alerta_operacao_nivel_bateria, Contagem de Colunas: 7\n",
      "Colunas:\n",
      "StructType([\n",
      "StructField('id_ft_alerta_operacao',LongType(), True), \\\n",
      "StructField('id_url',StringType(), True), \\\n",
      "StructField('id_dim_ambiente',LongType(), True), \\\n",
      "StructField('id_dim_colaborador',LongType(), True), \\\n",
      "StructField('status',IntegerType(), True), \\\n",
      "StructField('detalhe_alerta_operacao',StringType(), True), \\\n",
      "StructField('nivel',StringType(), True)])\n",
      "\n",
      "Nome da Tabela: ft_alerta_operacao_tarefas_nao_realizadas\n",
      "\n",
      "Critério de Agrupamento: ft_alerta_operacao_tarefas_nao_realizadas, Contagem de Colunas: 12\n",
      "Colunas:\n",
      "StructType([\n",
      "StructField('id_ft_alerta_operacao',LongType(), True), \\\n",
      "StructField('id_url',StringType(), True), \\\n",
      "StructField('id_dim_ambiente',LongType(), True), \\\n",
      "StructField('id_dim_colaborador',LongType(), True), \\\n",
      "StructField('id_dim_pdv',LongType(), True), \\\n",
      "StructField('id_ft_visita',LongType(), True), \\\n",
      "StructField('status',IntegerType(), True), \\\n",
      "StructField('detalhe_alerta_operacao',StringType(), True), \\\n",
      "StructField('data_roteiro',TimestampType(), True), \\\n",
      "StructField('data_entrada',TimestampType(), True), \\\n",
      "StructField('data_saida',TimestampType(), True), \\\n",
      "StructField('justificativa_tarefa',StringType(), True)])\n",
      "\n",
      "Nome da Tabela: ft_alerta_pesquisa\n",
      "\n",
      "Critério de Agrupamento: ft_alerta_pesquisa, Contagem de Colunas: 21\n",
      "Colunas:\n",
      "StructType([\n",
      "StructField('id_ft_alerta_pesquisa',LongType(), True), \\\n",
      "StructField('id_url',StringType(), True), \\\n",
      "StructField('id_dim_ambiente',LongType(), True), \\\n",
      "StructField('id_dim_pdv',LongType(), True), \\\n",
      "StructField('id_dim_colaborador',LongType(), True), \\\n",
      "StructField('id_dim_produto',LongType(), True), \\\n",
      "StructField('id_dim_linha_produto',LongType(), True), \\\n",
      "StructField('id_dim_marca',LongType(), True), \\\n",
      "StructField('id_dim_categoria_produto',LongType(), True), \\\n",
      "StructField('id_dim_super_categoria',LongType(), True), \\\n",
      "StructField('nivel',IntegerType(), True), \\\n",
      "StructField('data_processamento_alerta',TimestampType(), True), \\\n",
      "StructField('data',TimestampType(), True), \\\n",
      "StructField('previsao_solucao',TimestampType(), True), \\\n",
      "StructField('motivo_alerta',StringType(), True), \\\n",
      "StructField('valor_informado',StringType(), True), \\\n",
      "StructField('status',IntegerType(), True), \\\n",
      "StructField('data_expiracao',TimestampType(), True), \\\n",
      "StructField('data_fechamento',TimestampType(), True), \\\n",
      "StructField('tempo_fechamento',LongType(), True), \\\n",
      "StructField('observacao',StringType(), True)])\n",
      "\n",
      "Nome da Tabela: ft_alteracao_roteiro\n",
      "\n",
      "Critério de Agrupamento: ft_alteracao_roteiro, Contagem de Colunas: 10\n",
      "Colunas:\n",
      "StructType([\n",
      "StructField('if_ft_alteracao_roteiro',LongType(), True), \\\n",
      "StructField('id_url',LongType(), True), \\\n",
      "StructField('id_dim_ambiente',LongType(), True), \\\n",
      "StructField('id_dim_usuario_alterou',LongType(), True), \\\n",
      "StructField('id_dim_colaborador_alterado',LongType(), True), \\\n",
      "StructField('id_dim_pdv',LongType(), True), \\\n",
      "StructField('modo_adicao',StringType(), True), \\\n",
      "StructField('acao',StringType(), True), \\\n",
      "StructField('data',TimestampType(), True), \\\n",
      "StructField('detalhes',StringType(), True)])\n",
      "\n",
      "Nome da Tabela: ft_coleta\n",
      "\n",
      "Critério de Agrupamento: ft_coleta, Contagem de Colunas: 27\n",
      "Colunas:\n",
      "StructType([\n",
      "StructField('id_ft_coleta',LongType(), True), \\\n",
      "StructField('id_url',LongType(), True), \\\n",
      "StructField('id_dim_ambiente',LongType(), True), \\\n",
      "StructField('id_dim_formulario',LongType(), True), \\\n",
      "StructField('id_coleta',IntegerType(), True), \\\n",
      "StructField('id_dim_colaborador',LongType(), True), \\\n",
      "StructField('id_dim_pdv',LongType(), True), \\\n",
      "StructField('data',DateType(), True), \\\n",
      "StructField('rotulo',StringType(), True), \\\n",
      "StructField('data_solicitacao',TimestampType(), True), \\\n",
      "StructField('data_concluida',TimestampType(), True), \\\n",
      "StructField('data_expiracao',TimestampType(), True), \\\n",
      "StructField('tempo_gasto',LongType(), True), \\\n",
      "StructField('status',StringType(), True), \\\n",
      "StructField('analise',StringType(), True), \\\n",
      "StructField('usuario_analise',StringType(), True), \\\n",
      "StructField('data_analise',TimestampType(), True), \\\n",
      "StructField('justificada',IntegerType(), True), \\\n",
      "StructField('justificativa_tarefa',StringType(), True), \\\n",
      "StructField('data_justificativa_tarefa',TimestampType(), True), \\\n",
      "StructField('numero_fotos',IntegerType(), True), \\\n",
      "StructField('numero_fotos_sincronizadas',IntegerType(), True), \\\n",
      "StructField('respondida_expirada',IntegerType(), True), \\\n",
      "StructField('fl_excluido',IntegerType(), True), \\\n",
      "StructField('origem_coleta',StringType(), True), \\\n",
      "StructField('pendente',IntegerType(), True), \\\n",
      "StructField('aprovada',StringType(), True)])\n",
      "\n",
      "Nome da Tabela: ft_dado_coleta\n",
      "\n",
      "Critério de Agrupamento: ft_dado_coleta, Contagem de Colunas: 19\n",
      "Colunas:\n",
      "StructType([\n",
      "StructField('id_ft_dado_coleta',LongType(), True), \\\n",
      "StructField('id_url',LongType(), True), \\\n",
      "StructField('id_dim_ambiente',LongType(), True), \\\n",
      "StructField('id_dim_formulario',LongType(), True), \\\n",
      "StructField('id_dim_pergunta',LongType(), True), \\\n",
      "StructField('id_coleta',IntegerType(), True), \\\n",
      "StructField('id_dado_coleta',IntegerType(), True), \\\n",
      "StructField('id_dim_colaborador',LongType(), True), \\\n",
      "StructField('id_dim_pdv',LongType(), True), \\\n",
      "StructField('id_dim_produto',LongType(), True), \\\n",
      "StructField('id_dim_linha_produto',LongType(), True), \\\n",
      "StructField('id_dim_marca',LongType(), True), \\\n",
      "StructField('id_dim_categoria_produto',LongType(), True), \\\n",
      "StructField('id_dim_super_categoria',LongType(), True), \\\n",
      "StructField('data',TimestampType(), True), \\\n",
      "StructField('rotulo_coleta',StringType(), True), \\\n",
      "StructField('resposta',StringType(), True), \\\n",
      "StructField('score',DoubleType(), True), \\\n",
      "StructField('tempo_gasto',LongType(), True)])\n",
      "\n",
      "Nome da Tabela: ft_historico_acesso\n",
      "\n",
      "Critério de Agrupamento: ft_historico_acesso, Contagem de Colunas: 9\n",
      "Colunas:\n",
      "StructType([\n",
      "StructField('id_ft_historico_acesso',LongType(), True), \\\n",
      "StructField('id_url',StringType(), True), \\\n",
      "StructField('id_dim_ambiente',LongType(), True), \\\n",
      "StructField('id_dim_colaborador',LongType(), True), \\\n",
      "StructField('data',TimestampType(), True), \\\n",
      "StructField('tipo_acesso',IntegerType(), True), \\\n",
      "StructField('dt_login',TimestampType(), True), \\\n",
      "StructField('dt_logout',TimestampType(), True), \\\n",
      "StructField('tempo_logado',LongType(), True)])\n",
      "\n",
      "Nome da Tabela: ft_humor\n",
      "\n",
      "Critério de Agrupamento: ft_humor, Contagem de Colunas: 7\n",
      "Colunas:\n",
      "StructType([\n",
      "StructField('id_ft_humor',LongType(), True), \\\n",
      "StructField('id_url',LongType(), True), \\\n",
      "StructField('id_ambiente',IntegerType(), True), \\\n",
      "StructField('id_dim_colaborador',LongType(), True), \\\n",
      "StructField('id_humor',IntegerType(), True), \\\n",
      "StructField('data',DateType(), True), \\\n",
      "StructField('humor',StringType(), True)])\n",
      "\n",
      "Nome da Tabela: ft_metas\n",
      "\n",
      "Critério de Agrupamento: ft_metas, Contagem de Colunas: 27\n",
      "Colunas:\n",
      "StructType([\n",
      "StructField('id_ft_meta',LongType(), True), \\\n",
      "StructField('id_url',LongType(), True), \\\n",
      "StructField('id_dim_ambiente',LongType(), True), \\\n",
      "StructField('id_dim_colaborador',LongType(), True), \\\n",
      "StructField('id_dim_pdv',LongType(), True), \\\n",
      "StructField('id_dim_linha_produto',LongType(), True), \\\n",
      "StructField('id_dim_produto',LongType(), True), \\\n",
      "StructField('id_dim_marca',LongType(), True), \\\n",
      "StructField('id_dim_categoria',LongType(), True), \\\n",
      "StructField('data',DateType(), True), \\\n",
      "StructField('meta',DoubleType(), True), \\\n",
      "StructField('atingido',DoubleType(), True), \\\n",
      "StructField('meta_atingida',StringType(), True), \\\n",
      "StructField('registro_atual',StringType(), True), \\\n",
      "StructField('score_campo1',DoubleType(), True), \\\n",
      "StructField('score_campo2',DoubleType(), True), \\\n",
      "StructField('dt_aceite',DateType(), True), \\\n",
      "StructField('aceita',StringType(), True), \\\n",
      "StructField('dt_inicio',DateType(), True), \\\n",
      "StructField('dt_fim',DateType(), True), \\\n",
      "StructField('nome_coleta',StringType(), True), \\\n",
      "StructField('id_dim_pergunta',LongType(), True), \\\n",
      "StructField('id_dim_pergunta_dois',LongType(), True), \\\n",
      "StructField('nome_meta',StringType(), True), \\\n",
      "StructField('meta_ativa',StringType(), True), \\\n",
      "StructField('meta_base',DoubleType(), True), \\\n",
      "StructField('dt_atualizacao',TimestampType(), True)])\n",
      "\n",
      "Nome da Tabela: ft_roteiro\n",
      "\n",
      "Critério de Agrupamento: ft_roteiro, Contagem de Colunas: 17\n",
      "Colunas:\n",
      "StructType([\n",
      "StructField('id_ft_roteiro',LongType(), True), \\\n",
      "StructField('id_url',StringType(), True), \\\n",
      "StructField('id_dim_ambiente',LongType(), True), \\\n",
      "StructField('id_dim_pdv',LongType(), True), \\\n",
      "StructField('id_dim_colaborador',LongType(), True), \\\n",
      "StructField('tipo',IntegerType(), True), \\\n",
      "StructField('dia_semana',IntegerType(), True), \\\n",
      "StructField('semana',StringType(), True), \\\n",
      "StructField('data',TimestampType(), True), \\\n",
      "StructField('execucao_unica',StringType(), True), \\\n",
      "StructField('dt_limite',TimestampType(), True), \\\n",
      "StructField('ordem',IntegerType(), True), \\\n",
      "StructField('hora_entrada',TimestampType(), True), \\\n",
      "StructField('hora_saida',TimestampType(), True), \\\n",
      "StructField('tempo_planejado_pdv',LongType(), True), \\\n",
      "StructField('descricao',StringType(), True), \\\n",
      "StructField('periodo',IntegerType(), True)])\n",
      "\n",
      "Nome da Tabela: ft_status_day\n",
      "\n",
      "Critério de Agrupamento: ft_status_day, Contagem de Colunas: 50\n",
      "Colunas:\n",
      "StructType([\n",
      "StructField('id_ft_status_day',LongType(), True), \\\n",
      "StructField('id_url',LongType(), True), \\\n",
      "StructField('id_ambiente',IntegerType(), True), \\\n",
      "StructField('id_dim_colaborador',LongType() False), \\\n",
      "StructField('id_status_day',IntegerType(), True), \\\n",
      "StructField('data',DateType() False), \\\n",
      "StructField('id_afastamento',IntegerType(), True), \\\n",
      "StructField('dt_primeiro_check_in',TimestampType(), True), \\\n",
      "StructField('dt_primeiro_check_in_gps',TimestampType(), True), \\\n",
      "StructField('dt_ultimo_check_out',TimestampType(), True), \\\n",
      "StructField('dt_ultimo_check_out_gps',TimestampType(), True), \\\n",
      "StructField('tem_roteiro',IntegerType() False), \\\n",
      "StructField('logou_sistema_mobile',IntegerType() False), \\\n",
      "StructField('logou_sistema_web',IntegerType() False), \\\n",
      "StructField('respondeu_pesquisa',IntegerType() False), \\\n",
      "StructField('cumpriu_todos_roteiros',IntegerType() False), \\\n",
      "StructField('tempo_logado',LongType() False), \\\n",
      "StructField('tempo_logado_web',LongType() False), \\\n",
      "StructField('tempo_trabalho',LongType() False), \\\n",
      "StructField('tempo_em_loja',LongType() False), \\\n",
      "StructField('tempo_em_deslocamento',LongType() False), \\\n",
      "StructField('tempo_pesquisa',LongType() False), \\\n",
      "StructField('total_visitas',IntegerType() False), \\\n",
      "StructField('total_roteiros',IntegerType() False), \\\n",
      "StructField('total_pesquisas_pendentes',IntegerType() False), \\\n",
      "StructField('total_pesquisas_previstas',IntegerType() False), \\\n",
      "StructField('total_pesquisas',IntegerType() False), \\\n",
      "StructField('total_fotos',IntegerType() False), \\\n",
      "StructField('total_mensagens',IntegerType() False), \\\n",
      "StructField('total_faltas_justificadas',IntegerType(), True), \\\n",
      "StructField('total_faltas_justificadas_aprovadas',IntegerType(), True), \\\n",
      "StructField('esta_em_ferias',IntegerType() False), \\\n",
      "StructField('dt_criacao_registro',TimestampType() False), \\\n",
      "StructField('dt_ultima_modificacao_registro',TimestampType() False), \\\n",
      "StructField('tempo_em_loja_gps',LongType(), True), \\\n",
      "StructField('tempo_trabalho_gps',LongType(), True), \\\n",
      "StructField('tempo_em_deslocamento_gps',LongType(), True), \\\n",
      "StructField('total_visitas_gps',IntegerType(), True), \\\n",
      "StructField('cumpriu_todos_roteiros_gps',IntegerType(), True), \\\n",
      "StructField('total_roteiro_avulso',IntegerType(), True), \\\n",
      "StructField('total_visita_manual_avulso',IntegerType(), True), \\\n",
      "StructField('total_visita_gps_avulso',IntegerType(), True), \\\n",
      "StructField('mobile_ativo',IntegerType() False), \\\n",
      "StructField('dt_primeiro_login_mobile',TimestampType(), True), \\\n",
      "StructField('dt_primeiro_login_web',TimestampType(), True), \\\n",
      "StructField('primeiro_nivel_bateria',IntegerType(), True), \\\n",
      "StructField('ultimo_nivel_bateria',IntegerType(), True), \\\n",
      "StructField('id_dia_ponto_eletronico',IntegerType(), True), \\\n",
      "StructField('total_tempo_coleta',LongType(), True), \\\n",
      "StructField('dt_atualizacao_millis',LongType(), True)])\n",
      "\n",
      "Nome da Tabela: ft_visita\n",
      "\n",
      "Critério de Agrupamento: ft_visita, Contagem de Colunas: 26\n",
      "Colunas:\n",
      "StructType([\n",
      "StructField('id_ft_visita',LongType(), True), \\\n",
      "StructField('id_url',LongType(), True), \\\n",
      "StructField('id_ambiente',IntegerType(), True), \\\n",
      "StructField('id_dim_colaborador',LongType(), True), \\\n",
      "StructField('id_dim_ponto_de_venda',LongType(), True), \\\n",
      "StructField('id_visita',IntegerType(), True), \\\n",
      "StructField('data',TimestampType(), True), \\\n",
      "StructField('motivo_justificativa',StringType(), True), \\\n",
      "StructField('tipo_roteiro',StringType(), True), \\\n",
      "StructField('pesquisas_esperadas',IntegerType(), True), \\\n",
      "StructField('pesquisas_respondidas',IntegerType(), True), \\\n",
      "StructField('pesquisas_pendentes',IntegerType(), True), \\\n",
      "StructField('status',StringType(), True), \\\n",
      "StructField('tempo_total_coleta',LongType(), True), \\\n",
      "StructField('hora_esperada_entrada',TimestampType(), True), \\\n",
      "StructField('hora_esperada_saida',TimestampType(), True), \\\n",
      "StructField('atraso_entrada_checkin_manual_millis',LongType(), True), \\\n",
      "StructField('atraso_entrada_checkin_gps_millis',LongType(), True), \\\n",
      "StructField('duracao_planejada_millis',LongType(), True), \\\n",
      "StructField('data_entrada_checkin_manual',TimestampType(), True), \\\n",
      "StructField('data_saida_checkin_manual',TimestampType(), True), \\\n",
      "StructField('duracao_checkin_manual_millis',LongType(), True), \\\n",
      "StructField('data_entrada_checkin_gps',TimestampType(), True), \\\n",
      "StructField('data_saida_checkin_gps',TimestampType(), True), \\\n",
      "StructField('duracao_checkin_gps_millis',LongType(), True), \\\n",
      "StructField('checkout_sistema',IntegerType(), True)])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def clean_structure(structure):\n",
    "   \n",
    "    cleaned_structure = re.sub(r'(?<=[\\w\\d\\'\"])((?:\\s*,\\s*){2,})', ',', structure)\n",
    "    cleaned_structure = cleaned_structure.replace(\"',,\", \"',\")\n",
    "\n",
    "    return cleaned_structure\n",
    "\n",
    "def generate_schemas(file_name):\n",
    "    schemas = defaultdict(OrderedDict)\n",
    "\n",
    "    with open(file_name, mode='r', encoding=\"utf-8\") as csv_file:\n",
    "        csv_reader = csv.DictReader(csv_file, delimiter=';', quotechar='\"')\n",
    "\n",
    "        for row in csv_reader:\n",
    "            \n",
    "            table_name = row.get('Tabela', '').lower()\n",
    "            column_structure = row.get('estrutura', '').strip()\n",
    "\n",
    "          \n",
    "            column_structure = column_structure.replace(\n",
    "                \"StructField('\", \"StructField('\").replace(\",\",\"\").replace(\n",
    "                    \",, \",\",\").replace(\"' \",\"',\").replace(\"() True)\",\"(), True)\")\n",
    "\n",
    "            if column_structure:\n",
    "                if table_name not in schemas:\n",
    "                    schemas[table_name] = OrderedDict()\n",
    "                schemas[table_name][column_structure] = column_structure\n",
    "\n",
    "\n",
    "    for table_name, fields in schemas.items():\n",
    "        column_count = len(fields)\n",
    "        print(f\"Nome da Tabela: {table_name}\\n\")\n",
    "        formatted_fields = ', \\\\\\n'.join(fields.values())\n",
    "        formatted_schema = f\"StructType([\\n{formatted_fields}])\"\n",
    "        print(f\"Critério de Agrupamento: {table_name}, Contagem de Colunas: {column_count}\")\n",
    "        print(f\"Colunas:\\n{formatted_schema}\\n\")\n",
    "\n",
    "file_name = r\"C:\\mlflowjobs\\tabelas_teste.csv\"\n",
    "generate_schemas(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consulta para a tabela ft_alerta_operacao_horario_celular_diferente:\n",
      "\n",
      "    spark.sql('''SELECT \n",
      "                silver.involves_pnt.dim_colaborador(\n",
      "                id_ft_alerta_operacao,\n",
      "id_url,\n",
      "id_dim_ambiente,\n",
      "id_dim_colaborador,\n",
      "status,\n",
      "detalhe_alerta_operacao,\n",
      "modelo_celular,\n",
      "horario_celular,\n",
      "horario_atomico,\n",
      "                insertion_at  NOT NULL,\n",
      "                update_at  NOT NULL\n",
      "                )\n",
      "                FROM silver.seu_provider.ft_alerta_operacao_horario_celular_diferente\n",
      "                WHERE insertion_at = (SELECT MAX(insertion_at) FROM silver.seu_provider.ft_alerta_operacao_horario_celular_diferente)''')\n",
      "            \n",
      "\n",
      "Consulta para a tabela ft_alerta_operacao_nivel_bateria:\n",
      "\n",
      "    spark.sql('''SELECT \n",
      "                silver.involves_pnt.dim_colaborador(\n",
      "                id_ft_alerta_operacao,\n",
      "id_url,\n",
      "id_dim_ambiente,\n",
      "id_dim_colaborador,\n",
      "status,\n",
      "detalhe_alerta_operacao,\n",
      "nivel,\n",
      "                insertion_at  NOT NULL,\n",
      "                update_at  NOT NULL\n",
      "                )\n",
      "                FROM silver.seu_provider.ft_alerta_operacao_nivel_bateria\n",
      "                WHERE insertion_at = (SELECT MAX(insertion_at) FROM silver.seu_provider.ft_alerta_operacao_nivel_bateria)''')\n",
      "            \n",
      "\n",
      "Consulta para a tabela ft_alerta_operacao_tarefas_nao_realizadas:\n",
      "\n",
      "    spark.sql('''SELECT \n",
      "                silver.involves_pnt.dim_colaborador(\n",
      "                id_ft_alerta_operacao,\n",
      "id_url,\n",
      "id_dim_ambiente,\n",
      "id_dim_colaborador,\n",
      "id_dim_pdv,\n",
      "id_ft_visita,\n",
      "status,\n",
      "detalhe_alerta_operacao,\n",
      "data_roteiro,\n",
      "data_entrada,\n",
      "data_saida,\n",
      "justificativa_tarefa,\n",
      "                insertion_at  NOT NULL,\n",
      "                update_at  NOT NULL\n",
      "                )\n",
      "                FROM silver.seu_provider.ft_alerta_operacao_tarefas_nao_realizadas\n",
      "                WHERE insertion_at = (SELECT MAX(insertion_at) FROM silver.seu_provider.ft_alerta_operacao_tarefas_nao_realizadas)''')\n",
      "            \n",
      "\n",
      "Consulta para a tabela ft_alerta_pesquisa:\n",
      "\n",
      "    spark.sql('''SELECT \n",
      "                silver.involves_pnt.dim_colaborador(\n",
      "                id_ft_alerta_pesquisa,\n",
      "id_url,\n",
      "id_dim_ambiente,\n",
      "id_dim_pdv,\n",
      "id_dim_colaborador,\n",
      "id_dim_produto,\n",
      "id_dim_linha_produto,\n",
      "id_dim_marca,\n",
      "id_dim_categoria_produto,\n",
      "id_dim_super_categoria,\n",
      "nivel,\n",
      "data_processamento_alerta,\n",
      "data,\n",
      "previsao_solucao,\n",
      "motivo_alerta,\n",
      "valor_informado,\n",
      "status,\n",
      "data_expiracao,\n",
      "data_fechamento,\n",
      "tempo_fechamento,\n",
      "observacao,\n",
      "                insertion_at  NOT NULL,\n",
      "                update_at  NOT NULL\n",
      "                )\n",
      "                FROM silver.seu_provider.ft_alerta_pesquisa\n",
      "                WHERE insertion_at = (SELECT MAX(insertion_at) FROM silver.seu_provider.ft_alerta_pesquisa)''')\n",
      "            \n",
      "\n",
      "Consulta para a tabela ft_alteracao_roteiro:\n",
      "\n",
      "    spark.sql('''SELECT \n",
      "                silver.involves_pnt.dim_colaborador(\n",
      "                if_ft_alteracao_roteiro,\n",
      "id_url,\n",
      "id_dim_ambiente,\n",
      "id_dim_usuario_alterou,\n",
      "id_dim_colaborador_alterado,\n",
      "id_dim_pdv,\n",
      "modo_adicao,\n",
      "acao,\n",
      "data,\n",
      "detalhes,\n",
      "                insertion_at  NOT NULL,\n",
      "                update_at  NOT NULL\n",
      "                )\n",
      "                FROM silver.seu_provider.ft_alteracao_roteiro\n",
      "                WHERE insertion_at = (SELECT MAX(insertion_at) FROM silver.seu_provider.ft_alteracao_roteiro)''')\n",
      "            \n",
      "\n",
      "Consulta para a tabela ft_coleta:\n",
      "\n",
      "    spark.sql('''SELECT \n",
      "                silver.involves_pnt.dim_colaborador(\n",
      "                id_ft_coleta,\n",
      "id_url,\n",
      "id_dim_ambiente,\n",
      "id_dim_formulario,\n",
      "id_coleta,\n",
      "id_dim_colaborador,\n",
      "id_dim_pdv,\n",
      "data,\n",
      "rotulo,\n",
      "data_solicitacao,\n",
      "data_concluida,\n",
      "data_expiracao,\n",
      "tempo_gasto,\n",
      "status,\n",
      "analise,\n",
      "usuario_analise,\n",
      "data_analise,\n",
      "justificada,\n",
      "justificativa_tarefa,\n",
      "data_justificativa_tarefa,\n",
      "numero_fotos,\n",
      "numero_fotos_sincronizadas,\n",
      "respondida_expirada,\n",
      "fl_excluido,\n",
      "origem_coleta,\n",
      "pendente,\n",
      "aprovada,\n",
      "                insertion_at  NOT NULL,\n",
      "                update_at  NOT NULL\n",
      "                )\n",
      "                FROM silver.seu_provider.ft_coleta\n",
      "                WHERE insertion_at = (SELECT MAX(insertion_at) FROM silver.seu_provider.ft_coleta)''')\n",
      "            \n",
      "\n",
      "Consulta para a tabela ft_dado_coleta:\n",
      "\n",
      "    spark.sql('''SELECT \n",
      "                silver.involves_pnt.dim_colaborador(\n",
      "                id_ft_dado_coleta,\n",
      "id_url,\n",
      "id_dim_ambiente,\n",
      "id_dim_formulario,\n",
      "id_dim_pergunta,\n",
      "id_coleta,\n",
      "id_dado_coleta,\n",
      "id_dim_colaborador,\n",
      "id_dim_pdv,\n",
      "id_dim_produto,\n",
      "id_dim_linha_produto,\n",
      "id_dim_marca,\n",
      "id_dim_categoria_produto,\n",
      "id_dim_super_categoria,\n",
      "data,\n",
      "rotulo_coleta,\n",
      "resposta,\n",
      "score,\n",
      "tempo_gasto,\n",
      "                insertion_at  NOT NULL,\n",
      "                update_at  NOT NULL\n",
      "                )\n",
      "                FROM silver.seu_provider.ft_dado_coleta\n",
      "                WHERE insertion_at = (SELECT MAX(insertion_at) FROM silver.seu_provider.ft_dado_coleta)''')\n",
      "            \n",
      "\n",
      "Consulta para a tabela ft_historico_acesso:\n",
      "\n",
      "    spark.sql('''SELECT \n",
      "                silver.involves_pnt.dim_colaborador(\n",
      "                id_ft_historico_acesso,\n",
      "id_url,\n",
      "id_dim_ambiente,\n",
      "id_dim_colaborador,\n",
      "data,\n",
      "tipo_acesso,\n",
      "dt_login,\n",
      "dt_logout,\n",
      "tempo_logado,\n",
      "                insertion_at  NOT NULL,\n",
      "                update_at  NOT NULL\n",
      "                )\n",
      "                FROM silver.seu_provider.ft_historico_acesso\n",
      "                WHERE insertion_at = (SELECT MAX(insertion_at) FROM silver.seu_provider.ft_historico_acesso)''')\n",
      "            \n",
      "\n",
      "Consulta para a tabela ft_humor:\n",
      "\n",
      "    spark.sql('''SELECT \n",
      "                silver.involves_pnt.dim_colaborador(\n",
      "                id_ft_humor,\n",
      "id_url,\n",
      "id_ambiente,\n",
      "id_dim_colaborador,\n",
      "id_humor,\n",
      "data,\n",
      "humor,\n",
      "                insertion_at  NOT NULL,\n",
      "                update_at  NOT NULL\n",
      "                )\n",
      "                FROM silver.seu_provider.ft_humor\n",
      "                WHERE insertion_at = (SELECT MAX(insertion_at) FROM silver.seu_provider.ft_humor)''')\n",
      "            \n",
      "\n",
      "Consulta para a tabela ft_metas:\n",
      "\n",
      "    spark.sql('''SELECT \n",
      "                silver.involves_pnt.dim_colaborador(\n",
      "                id_ft_meta,\n",
      "id_url,\n",
      "id_dim_ambiente,\n",
      "id_dim_colaborador,\n",
      "id_dim_pdv,\n",
      "id_dim_linha_produto,\n",
      "id_dim_produto,\n",
      "id_dim_marca,\n",
      "id_dim_categoria,\n",
      "data,\n",
      "meta,\n",
      "atingido,\n",
      "meta_atingida,\n",
      "registro_atual,\n",
      "score_campo1,\n",
      "score_campo2,\n",
      "dt_aceite,\n",
      "aceita,\n",
      "dt_inicio,\n",
      "dt_fim,\n",
      "nome_coleta,\n",
      "id_dim_pergunta,\n",
      "id_dim_pergunta_dois,\n",
      "nome_meta,\n",
      "meta_ativa,\n",
      "meta_base,\n",
      "dt_atualizacao,\n",
      "                insertion_at  NOT NULL,\n",
      "                update_at  NOT NULL\n",
      "                )\n",
      "                FROM silver.seu_provider.ft_metas\n",
      "                WHERE insertion_at = (SELECT MAX(insertion_at) FROM silver.seu_provider.ft_metas)''')\n",
      "            \n",
      "\n",
      "Consulta para a tabela ft_roteiro:\n",
      "\n",
      "    spark.sql('''SELECT \n",
      "                silver.involves_pnt.dim_colaborador(\n",
      "                id_ft_roteiro,\n",
      "id_url,\n",
      "id_dim_ambiente,\n",
      "id_dim_pdv,\n",
      "id_dim_colaborador,\n",
      "tipo,\n",
      "dia_semana,\n",
      "semana,\n",
      "data,\n",
      "execucao_unica,\n",
      "dt_limite,\n",
      "ordem,\n",
      "hora_entrada,\n",
      "hora_saida,\n",
      "tempo_planejado_pdv,\n",
      "descricao,\n",
      "periodo,\n",
      "                insertion_at  NOT NULL,\n",
      "                update_at  NOT NULL\n",
      "                )\n",
      "                FROM silver.seu_provider.ft_roteiro\n",
      "                WHERE insertion_at = (SELECT MAX(insertion_at) FROM silver.seu_provider.ft_roteiro)''')\n",
      "            \n",
      "\n",
      "Consulta para a tabela ft_status_day:\n",
      "\n",
      "    spark.sql('''SELECT \n",
      "                silver.involves_pnt.dim_colaborador(\n",
      "                id_ft_status_day,\n",
      "id_url,\n",
      "id_ambiente,\n",
      "id_dim_colaborador,\n",
      "id_status_day,\n",
      "data,\n",
      "id_afastamento,\n",
      "dt_primeiro_check_in,\n",
      "dt_primeiro_check_in_gps,\n",
      "dt_ultimo_check_out,\n",
      "dt_ultimo_check_out_gps,\n",
      "tem_roteiro,\n",
      "logou_sistema_mobile,\n",
      "logou_sistema_web,\n",
      "respondeu_pesquisa,\n",
      "cumpriu_todos_roteiros,\n",
      "tempo_logado,\n",
      "tempo_logado_web,\n",
      "tempo_trabalho,\n",
      "tempo_em_loja,\n",
      "tempo_em_deslocamento,\n",
      "tempo_pesquisa,\n",
      "total_visitas,\n",
      "total_roteiros,\n",
      "total_pesquisas_pendentes,\n",
      "total_pesquisas_previstas,\n",
      "total_pesquisas,\n",
      "total_fotos,\n",
      "total_mensagens,\n",
      "total_faltas_justificadas,\n",
      "total_faltas_justificadas_aprovadas,\n",
      "esta_em_ferias,\n",
      "dt_criacao_registro,\n",
      "dt_ultima_modificacao_registro,\n",
      "tempo_em_loja_gps,\n",
      "tempo_trabalho_gps,\n",
      "tempo_em_deslocamento_gps,\n",
      "total_visitas_gps,\n",
      "cumpriu_todos_roteiros_gps,\n",
      "total_roteiro_avulso,\n",
      "total_visita_manual_avulso,\n",
      "total_visita_gps_avulso,\n",
      "mobile_ativo,\n",
      "dt_primeiro_login_mobile,\n",
      "dt_primeiro_login_web,\n",
      "primeiro_nivel_bateria,\n",
      "ultimo_nivel_bateria,\n",
      "id_dia_ponto_eletronico,\n",
      "total_tempo_coleta,\n",
      "dt_atualizacao_millis,\n",
      "                insertion_at  NOT NULL,\n",
      "                update_at  NOT NULL\n",
      "                )\n",
      "                FROM silver.seu_provider.ft_status_day\n",
      "                WHERE insertion_at = (SELECT MAX(insertion_at) FROM silver.seu_provider.ft_status_day)''')\n",
      "            \n",
      "\n",
      "Consulta para a tabela ft_visita:\n",
      "\n",
      "    spark.sql('''SELECT \n",
      "                silver.involves_pnt.dim_colaborador(\n",
      "                id_ft_visita,\n",
      "id_url,\n",
      "id_ambiente,\n",
      "id_dim_colaborador,\n",
      "id_dim_ponto_de_venda,\n",
      "id_visita,\n",
      "data,\n",
      "motivo_justificativa,\n",
      "tipo_roteiro,\n",
      "pesquisas_esperadas,\n",
      "pesquisas_respondidas,\n",
      "pesquisas_pendentes,\n",
      "status,\n",
      "tempo_total_coleta,\n",
      "hora_esperada_entrada,\n",
      "hora_esperada_saida,\n",
      "atraso_entrada_checkin_manual_millis,\n",
      "atraso_entrada_checkin_gps_millis,\n",
      "duracao_planejada_millis,\n",
      "data_entrada_checkin_manual,\n",
      "data_saida_checkin_manual,\n",
      "duracao_checkin_manual_millis,\n",
      "data_entrada_checkin_gps,\n",
      "data_saida_checkin_gps,\n",
      "duracao_checkin_gps_millis,\n",
      "checkout_sistema,\n",
      "                insertion_at  NOT NULL,\n",
      "                update_at  NOT NULL\n",
      "                )\n",
      "                FROM silver.seu_provider.ft_visita\n",
      "                WHERE insertion_at = (SELECT MAX(insertion_at) FROM silver.seu_provider.ft_visita)''')\n",
      "            \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def clean_structure(structure):\n",
    "    cleaned_structure = re.sub(r'(?<=[\\w\\d\\'\"])((?:\\s*,\\s*){2,})', ',', structure)\n",
    "    cleaned_structure = cleaned_structure.replace(\"',,\", \"',\")\n",
    "    return cleaned_structure\n",
    "\n",
    "def generate_sql_queries(file_name):\n",
    "    with open(file_name, mode='r', encoding=\"utf-8\") as csv_file:\n",
    "        csv_reader = csv.DictReader(csv_file, delimiter=';', quotechar='\"')\n",
    "\n",
    "        queries = defaultdict(list)\n",
    "\n",
    "        for row in csv_reader:\n",
    "            table_name = row.get('Tabela', '').lower()\n",
    "            column_structure = row.get('estrutura', '').strip().replace(\"StructField('\",\"\").split(\"',\")[0]\n",
    "\n",
    "            if column_structure:\n",
    "\n",
    "                column_structure = clean_structure(column_structure)\n",
    "\n",
    "                queries[table_name].append(column_structure)\n",
    "\n",
    "        for table_name, columns in queries.items():\n",
    "  \n",
    "            column_names = ',\\n'.join(columns)\n",
    "\n",
    "            query = f\"\"\"\n",
    "    spark.sql('''SELECT \n",
    "                silver.involves_pnt.dim_colaborador(\n",
    "                {column_names},\n",
    "                insertion_at  NOT NULL,\n",
    "                update_at  NOT NULL\n",
    "                )\n",
    "                FROM silver.{providerName}.{table_name}\n",
    "                WHERE insertion_at = (SELECT MAX(insertion_at) FROM silver.{providerName}.{table_name})''')\n",
    "            \"\"\"\n",
    "            print(f\"Consulta para a tabela {table_name}:\\n{query}\\n\")\n",
    "\n",
    "file_name = r\"C:\\mlflowjobs\\tabelas_teste.csv\"\n",
    "providerName = \"seu_provider\"\n",
    "generate_sql_queries(file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%sql\n",
      "CREATE TABLE IF NOT EXISTS silver.involves_pnt.ft_alerta_operacao_horario_celular_diferente (\n",
      "id_ft_alerta_operacao,\n",
      "id_url,\n",
      "id_dim_ambiente,\n",
      "id_dim_colaborador,\n",
      "status,\n",
      "detalhe_alerta_operacao,\n",
      "modelo_celular,\n",
      "horario_celular,\n",
      "horario_atomico,\n",
      "insertion_at TIMESTAMP NOT NULL\n",
      ")\n",
      "%sql\n",
      "CREATE TABLE IF NOT EXISTS silver.involves_pnt.ft_alerta_operacao_nivel_bateria (\n",
      "id_ft_alerta_operacao,\n",
      "id_url,\n",
      "id_dim_ambiente,\n",
      "id_dim_colaborador,\n",
      "status,\n",
      "detalhe_alerta_operacao,\n",
      "nivel,\n",
      "insertion_at TIMESTAMP NOT NULL\n",
      ")\n",
      "%sql\n",
      "CREATE TABLE IF NOT EXISTS silver.involves_pnt.ft_alerta_operacao_tarefas_nao_realizadas (\n",
      "id_ft_alerta_operacao,\n",
      "id_url,\n",
      "id_dim_ambiente,\n",
      "id_dim_colaborador,\n",
      "id_dim_pdv,\n",
      "id_ft_visita,\n",
      "status,\n",
      "detalhe_alerta_operacao,\n",
      "data_roteiro,\n",
      "data_entrada,\n",
      "data_saida,\n",
      "justificativa_tarefa,\n",
      "insertion_at TIMESTAMP NOT NULL\n",
      ")\n",
      "%sql\n",
      "CREATE TABLE IF NOT EXISTS silver.involves_pnt.ft_alerta_pesquisa (\n",
      "id_ft_alerta_pesquisa,\n",
      "id_url,\n",
      "id_dim_ambiente,\n",
      "id_dim_pdv,\n",
      "id_dim_colaborador,\n",
      "id_dim_produto,\n",
      "id_dim_linha_produto,\n",
      "id_dim_marca,\n",
      "id_dim_categoria_produto,\n",
      "id_dim_super_categoria,\n",
      "nivel,\n",
      "data_processamento_alerta,\n",
      "data,\n",
      "previsao_solucao,\n",
      "motivo_alerta,\n",
      "valor_informado,\n",
      "status,\n",
      "data_expiracao,\n",
      "data_fechamento,\n",
      "tempo_fechamento,\n",
      "observacao,\n",
      "insertion_at TIMESTAMP NOT NULL\n",
      ")\n",
      "%sql\n",
      "CREATE TABLE IF NOT EXISTS silver.involves_pnt.ft_alteracao_roteiro (\n",
      "if_ft_alteracao_roteiro,\n",
      "id_url,\n",
      "id_dim_ambiente,\n",
      "id_dim_usuario_alterou,\n",
      "id_dim_colaborador_alterado,\n",
      "id_dim_pdv,\n",
      "modo_adicao,\n",
      "acao,\n",
      "data,\n",
      "detalhes,\n",
      "insertion_at TIMESTAMP NOT NULL\n",
      ")\n",
      "%sql\n",
      "CREATE TABLE IF NOT EXISTS silver.involves_pnt.ft_coleta (\n",
      "id_ft_coleta,\n",
      "id_url,\n",
      "id_dim_ambiente,\n",
      "id_dim_formulario,\n",
      "id_coleta,\n",
      "id_dim_colaborador,\n",
      "id_dim_pdv,\n",
      "data,\n",
      "rotulo,\n",
      "data_solicitacao,\n",
      "data_concluida,\n",
      "data_expiracao,\n",
      "tempo_gasto,\n",
      "status,\n",
      "analise,\n",
      "usuario_analise,\n",
      "data_analise,\n",
      "justificada,\n",
      "justificativa_tarefa,\n",
      "data_justificativa_tarefa,\n",
      "numero_fotos,\n",
      "numero_fotos_sincronizadas,\n",
      "respondida_expirada,\n",
      "fl_excluido,\n",
      "origem_coleta,\n",
      "pendente,\n",
      "aprovada,\n",
      "insertion_at TIMESTAMP NOT NULL\n",
      ")\n",
      "%sql\n",
      "CREATE TABLE IF NOT EXISTS silver.involves_pnt.ft_dado_coleta (\n",
      "id_ft_dado_coleta,\n",
      "id_url,\n",
      "id_dim_ambiente,\n",
      "id_dim_formulario,\n",
      "id_dim_pergunta,\n",
      "id_coleta,\n",
      "id_dado_coleta,\n",
      "id_dim_colaborador,\n",
      "id_dim_pdv,\n",
      "id_dim_produto,\n",
      "id_dim_linha_produto,\n",
      "id_dim_marca,\n",
      "id_dim_categoria_produto,\n",
      "id_dim_super_categoria,\n",
      "data,\n",
      "rotulo_coleta,\n",
      "resposta,\n",
      "score,\n",
      "tempo_gasto,\n",
      "insertion_at TIMESTAMP NOT NULL\n",
      ")\n",
      "%sql\n",
      "CREATE TABLE IF NOT EXISTS silver.involves_pnt.ft_historico_acesso (\n",
      "id_ft_historico_acesso,\n",
      "id_url,\n",
      "id_dim_ambiente,\n",
      "id_dim_colaborador,\n",
      "data,\n",
      "tipo_acesso,\n",
      "dt_login,\n",
      "dt_logout,\n",
      "tempo_logado,\n",
      "insertion_at TIMESTAMP NOT NULL\n",
      ")\n",
      "%sql\n",
      "CREATE TABLE IF NOT EXISTS silver.involves_pnt.ft_humor (\n",
      "id_ft_humor,\n",
      "id_url,\n",
      "id_ambiente,\n",
      "id_dim_colaborador,\n",
      "id_humor,\n",
      "data,\n",
      "humor,\n",
      "insertion_at TIMESTAMP NOT NULL\n",
      ")\n",
      "%sql\n",
      "CREATE TABLE IF NOT EXISTS silver.involves_pnt.ft_metas (\n",
      "id_ft_meta,\n",
      "id_url,\n",
      "id_dim_ambiente,\n",
      "id_dim_colaborador,\n",
      "id_dim_pdv,\n",
      "id_dim_linha_produto,\n",
      "id_dim_produto,\n",
      "id_dim_marca,\n",
      "id_dim_categoria,\n",
      "data,\n",
      "meta,\n",
      "atingido,\n",
      "meta_atingida,\n",
      "registro_atual,\n",
      "score_campo1,\n",
      "score_campo2,\n",
      "dt_aceite,\n",
      "aceita,\n",
      "dt_inicio,\n",
      "dt_fim,\n",
      "nome_coleta,\n",
      "id_dim_pergunta,\n",
      "id_dim_pergunta_dois,\n",
      "nome_meta,\n",
      "meta_ativa,\n",
      "meta_base,\n",
      "dt_atualizacao,\n",
      "insertion_at TIMESTAMP NOT NULL\n",
      ")\n",
      "%sql\n",
      "CREATE TABLE IF NOT EXISTS silver.involves_pnt.ft_roteiro (\n",
      "id_ft_roteiro,\n",
      "id_url,\n",
      "id_dim_ambiente,\n",
      "id_dim_pdv,\n",
      "id_dim_colaborador,\n",
      "tipo,\n",
      "dia_semana,\n",
      "semana,\n",
      "data,\n",
      "execucao_unica,\n",
      "dt_limite,\n",
      "ordem,\n",
      "hora_entrada,\n",
      "hora_saida,\n",
      "tempo_planejado_pdv,\n",
      "descricao,\n",
      "periodo,\n",
      "insertion_at TIMESTAMP NOT NULL\n",
      ")\n",
      "%sql\n",
      "CREATE TABLE IF NOT EXISTS silver.involves_pnt.ft_status_day (\n",
      "id_ft_status_day,\n",
      "id_url,\n",
      "id_ambiente,\n",
      "id_dim_colaborador,\n",
      "id_status_day,\n",
      "data,\n",
      "id_afastamento,\n",
      "dt_primeiro_check_in,\n",
      "dt_primeiro_check_in_gps,\n",
      "dt_ultimo_check_out,\n",
      "dt_ultimo_check_out_gps,\n",
      "tem_roteiro,\n",
      "logou_sistema_mobile,\n",
      "logou_sistema_web,\n",
      "respondeu_pesquisa,\n",
      "cumpriu_todos_roteiros,\n",
      "tempo_logado,\n",
      "tempo_logado_web,\n",
      "tempo_trabalho,\n",
      "tempo_em_loja,\n",
      "tempo_em_deslocamento,\n",
      "tempo_pesquisa,\n",
      "total_visitas,\n",
      "total_roteiros,\n",
      "total_pesquisas_pendentes,\n",
      "total_pesquisas_previstas,\n",
      "total_pesquisas,\n",
      "total_fotos,\n",
      "total_mensagens,\n",
      "total_faltas_justificadas,\n",
      "total_faltas_justificadas_aprovadas,\n",
      "esta_em_ferias,\n",
      "dt_criacao_registro,\n",
      "dt_ultima_modificacao_registro,\n",
      "tempo_em_loja_gps,\n",
      "tempo_trabalho_gps,\n",
      "tempo_em_deslocamento_gps,\n",
      "total_visitas_gps,\n",
      "cumpriu_todos_roteiros_gps,\n",
      "total_roteiro_avulso,\n",
      "total_visita_manual_avulso,\n",
      "total_visita_gps_avulso,\n",
      "mobile_ativo,\n",
      "dt_primeiro_login_mobile,\n",
      "dt_primeiro_login_web,\n",
      "primeiro_nivel_bateria,\n",
      "ultimo_nivel_bateria,\n",
      "id_dia_ponto_eletronico,\n",
      "total_tempo_coleta,\n",
      "dt_atualizacao_millis,\n",
      "insertion_at TIMESTAMP NOT NULL\n",
      ")\n",
      "%sql\n",
      "CREATE TABLE IF NOT EXISTS silver.involves_pnt.ft_visita (\n",
      "id_ft_visita,\n",
      "id_url,\n",
      "id_ambiente,\n",
      "id_dim_colaborador,\n",
      "id_dim_ponto_de_venda,\n",
      "id_visita,\n",
      "data,\n",
      "motivo_justificativa,\n",
      "tipo_roteiro,\n",
      "pesquisas_esperadas,\n",
      "pesquisas_respondidas,\n",
      "pesquisas_pendentes,\n",
      "status,\n",
      "tempo_total_coleta,\n",
      "hora_esperada_entrada,\n",
      "hora_esperada_saida,\n",
      "atraso_entrada_checkin_manual_millis,\n",
      "atraso_entrada_checkin_gps_millis,\n",
      "duracao_planejada_millis,\n",
      "data_entrada_checkin_manual,\n",
      "data_saida_checkin_manual,\n",
      "duracao_checkin_manual_millis,\n",
      "data_entrada_checkin_gps,\n",
      "data_saida_checkin_gps,\n",
      "duracao_checkin_gps_millis,\n",
      "checkout_sistema,\n",
      "insertion_at TIMESTAMP NOT NULL\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def clean_structure(structure):\n",
    "    cleaned_structure = re.sub(r'(?<=[\\w\\d\\'\"])((?:\\s*,\\s*){2,})', ',', structure)\n",
    "    cleaned_structure = cleaned_structure.replace(\"',,\", \"',\")\n",
    "    return cleaned_structure\n",
    "\n",
    "def generate_sql_create_table(file_name):\n",
    "    with open(file_name, mode='r', encoding=\"utf-8\") as csv_file:\n",
    "        csv_reader = csv.DictReader(csv_file, delimiter=';', quotechar='\"')\n",
    "\n",
    "        table_columns = defaultdict(list)\n",
    "\n",
    "        for row in csv_reader:\n",
    "            table_name = row.get('Tabela', '').lower()\n",
    "            column_structure = row.get('estrutura', '').strip().replace(\"StructField('\",\"\").split(\"',\")[0]\n",
    "\n",
    "            if column_structure:\n",
    "                column_structure = clean_structure(column_structure)\n",
    "                table_columns[table_name].append(column_structure)\n",
    "\n",
    "        sql_statements = []\n",
    "\n",
    "        for table_name, columns in table_columns.items():\n",
    "            columns.append(\"insertion_at TIMESTAMP NOT NULL\")\n",
    "            column_names = ',\\n'.join(columns)\n",
    "            sql_statement = f\"%sql\\nCREATE TABLE IF NOT EXISTS silver.involves_pnt.{table_name} (\\n{column_names}\\n)\"\n",
    "            sql_statements.append(sql_statement)\n",
    "\n",
    "        return sql_statements\n",
    "\n",
    "\n",
    "file_name = r\"C:\\mlflowjobs\\tabelas_teste.csv\"\n",
    "providerName = \"seu_provider\"\n",
    "sql_create_table_statements = generate_sql_create_table(file_name)\n",
    "\n",
    "for statement in sql_create_table_statements:\n",
    "    print(statement)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Código de conversão para a tabela ft_alerta_operacao_horario_celular_diferente:\n",
      "\n",
      "            from pyspark.sql.functions import col, regexp_replace\n",
      "            from pyspark.sql.types import DoubleType, FloatType\n",
      "            from pyspark.sql import DataFrame\n",
      "\n",
      "            # Substitua 'df' pelo DataFrame real\n",
      "            df = ...\n",
      "\n",
      "            columns_to_process = [\n",
      "                \n",
      "            ]\n",
      "\n",
      "            def replace_comma_with_period_and_cast(column: str) -> col:\n",
      "                return col(column).cast(DoubleType() if 'DoubleType()' in column else FloatType()).alias(column)\n",
      "\n",
      "            for column_name in columns_to_process:\n",
      "                df = df.withColumn(\n",
      "                    column_name,\n",
      "                    regexp_replace(col(column_name), \",\", \".\").cast(DoubleType() if 'DoubleType()' in column_name else FloatType())\n",
      "                )\n",
      "            \n",
      "\n",
      "Código de conversão para a tabela ft_alerta_operacao_nivel_bateria:\n",
      "\n",
      "            from pyspark.sql.functions import col, regexp_replace\n",
      "            from pyspark.sql.types import DoubleType, FloatType\n",
      "            from pyspark.sql import DataFrame\n",
      "\n",
      "            # Substitua 'df' pelo DataFrame real\n",
      "            df = ...\n",
      "\n",
      "            columns_to_process = [\n",
      "                \n",
      "            ]\n",
      "\n",
      "            def replace_comma_with_period_and_cast(column: str) -> col:\n",
      "                return col(column).cast(DoubleType() if 'DoubleType()' in column else FloatType()).alias(column)\n",
      "\n",
      "            for column_name in columns_to_process:\n",
      "                df = df.withColumn(\n",
      "                    column_name,\n",
      "                    regexp_replace(col(column_name), \",\", \".\").cast(DoubleType() if 'DoubleType()' in column_name else FloatType())\n",
      "                )\n",
      "            \n",
      "\n",
      "Código de conversão para a tabela ft_alerta_operacao_tarefas_nao_realizadas:\n",
      "\n",
      "            from pyspark.sql.functions import col, regexp_replace\n",
      "            from pyspark.sql.types import DoubleType, FloatType\n",
      "            from pyspark.sql import DataFrame\n",
      "\n",
      "            # Substitua 'df' pelo DataFrame real\n",
      "            df = ...\n",
      "\n",
      "            columns_to_process = [\n",
      "                \n",
      "            ]\n",
      "\n",
      "            def replace_comma_with_period_and_cast(column: str) -> col:\n",
      "                return col(column).cast(DoubleType() if 'DoubleType()' in column else FloatType()).alias(column)\n",
      "\n",
      "            for column_name in columns_to_process:\n",
      "                df = df.withColumn(\n",
      "                    column_name,\n",
      "                    regexp_replace(col(column_name), \",\", \".\").cast(DoubleType() if 'DoubleType()' in column_name else FloatType())\n",
      "                )\n",
      "            \n",
      "\n",
      "Código de conversão para a tabela ft_alerta_pesquisa:\n",
      "\n",
      "            from pyspark.sql.functions import col, regexp_replace\n",
      "            from pyspark.sql.types import DoubleType, FloatType\n",
      "            from pyspark.sql import DataFrame\n",
      "\n",
      "            # Substitua 'df' pelo DataFrame real\n",
      "            df = ...\n",
      "\n",
      "            columns_to_process = [\n",
      "                \n",
      "            ]\n",
      "\n",
      "            def replace_comma_with_period_and_cast(column: str) -> col:\n",
      "                return col(column).cast(DoubleType() if 'DoubleType()' in column else FloatType()).alias(column)\n",
      "\n",
      "            for column_name in columns_to_process:\n",
      "                df = df.withColumn(\n",
      "                    column_name,\n",
      "                    regexp_replace(col(column_name), \",\", \".\").cast(DoubleType() if 'DoubleType()' in column_name else FloatType())\n",
      "                )\n",
      "            \n",
      "\n",
      "Código de conversão para a tabela ft_alteracao_roteiro:\n",
      "\n",
      "            from pyspark.sql.functions import col, regexp_replace\n",
      "            from pyspark.sql.types import DoubleType, FloatType\n",
      "            from pyspark.sql import DataFrame\n",
      "\n",
      "            # Substitua 'df' pelo DataFrame real\n",
      "            df = ...\n",
      "\n",
      "            columns_to_process = [\n",
      "                \n",
      "            ]\n",
      "\n",
      "            def replace_comma_with_period_and_cast(column: str) -> col:\n",
      "                return col(column).cast(DoubleType() if 'DoubleType()' in column else FloatType()).alias(column)\n",
      "\n",
      "            for column_name in columns_to_process:\n",
      "                df = df.withColumn(\n",
      "                    column_name,\n",
      "                    regexp_replace(col(column_name), \",\", \".\").cast(DoubleType() if 'DoubleType()' in column_name else FloatType())\n",
      "                )\n",
      "            \n",
      "\n",
      "Código de conversão para a tabela ft_coleta:\n",
      "\n",
      "            from pyspark.sql.functions import col, regexp_replace\n",
      "            from pyspark.sql.types import DoubleType, FloatType\n",
      "            from pyspark.sql import DataFrame\n",
      "\n",
      "            # Substitua 'df' pelo DataFrame real\n",
      "            df = ...\n",
      "\n",
      "            columns_to_process = [\n",
      "                \n",
      "            ]\n",
      "\n",
      "            def replace_comma_with_period_and_cast(column: str) -> col:\n",
      "                return col(column).cast(DoubleType() if 'DoubleType()' in column else FloatType()).alias(column)\n",
      "\n",
      "            for column_name in columns_to_process:\n",
      "                df = df.withColumn(\n",
      "                    column_name,\n",
      "                    regexp_replace(col(column_name), \",\", \".\").cast(DoubleType() if 'DoubleType()' in column_name else FloatType())\n",
      "                )\n",
      "            \n",
      "\n",
      "Código de conversão para a tabela ft_dado_coleta:\n",
      "\n",
      "            from pyspark.sql.functions import col, regexp_replace\n",
      "            from pyspark.sql.types import DoubleType, FloatType\n",
      "            from pyspark.sql import DataFrame\n",
      "\n",
      "            # Substitua 'df' pelo DataFrame real\n",
      "            df = ...\n",
      "\n",
      "            columns_to_process = [\n",
      "                \n",
      "            ]\n",
      "\n",
      "            def replace_comma_with_period_and_cast(column: str) -> col:\n",
      "                return col(column).cast(DoubleType() if 'DoubleType()' in column else FloatType()).alias(column)\n",
      "\n",
      "            for column_name in columns_to_process:\n",
      "                df = df.withColumn(\n",
      "                    column_name,\n",
      "                    regexp_replace(col(column_name), \",\", \".\").cast(DoubleType() if 'DoubleType()' in column_name else FloatType())\n",
      "                )\n",
      "            \n",
      "\n",
      "Código de conversão para a tabela ft_historico_acesso:\n",
      "\n",
      "            from pyspark.sql.functions import col, regexp_replace\n",
      "            from pyspark.sql.types import DoubleType, FloatType\n",
      "            from pyspark.sql import DataFrame\n",
      "\n",
      "            # Substitua 'df' pelo DataFrame real\n",
      "            df = ...\n",
      "\n",
      "            columns_to_process = [\n",
      "                \n",
      "            ]\n",
      "\n",
      "            def replace_comma_with_period_and_cast(column: str) -> col:\n",
      "                return col(column).cast(DoubleType() if 'DoubleType()' in column else FloatType()).alias(column)\n",
      "\n",
      "            for column_name in columns_to_process:\n",
      "                df = df.withColumn(\n",
      "                    column_name,\n",
      "                    regexp_replace(col(column_name), \",\", \".\").cast(DoubleType() if 'DoubleType()' in column_name else FloatType())\n",
      "                )\n",
      "            \n",
      "\n",
      "Código de conversão para a tabela ft_humor:\n",
      "\n",
      "            from pyspark.sql.functions import col, regexp_replace\n",
      "            from pyspark.sql.types import DoubleType, FloatType\n",
      "            from pyspark.sql import DataFrame\n",
      "\n",
      "            # Substitua 'df' pelo DataFrame real\n",
      "            df = ...\n",
      "\n",
      "            columns_to_process = [\n",
      "                \n",
      "            ]\n",
      "\n",
      "            def replace_comma_with_period_and_cast(column: str) -> col:\n",
      "                return col(column).cast(DoubleType() if 'DoubleType()' in column else FloatType()).alias(column)\n",
      "\n",
      "            for column_name in columns_to_process:\n",
      "                df = df.withColumn(\n",
      "                    column_name,\n",
      "                    regexp_replace(col(column_name), \",\", \".\").cast(DoubleType() if 'DoubleType()' in column_name else FloatType())\n",
      "                )\n",
      "            \n",
      "\n",
      "Código de conversão para a tabela ft_metas:\n",
      "\n",
      "            from pyspark.sql.functions import col, regexp_replace\n",
      "            from pyspark.sql.types import DoubleType, FloatType\n",
      "            from pyspark.sql import DataFrame\n",
      "\n",
      "            # Substitua 'df' pelo DataFrame real\n",
      "            df = ...\n",
      "\n",
      "            columns_to_process = [\n",
      "                \n",
      "            ]\n",
      "\n",
      "            def replace_comma_with_period_and_cast(column: str) -> col:\n",
      "                return col(column).cast(DoubleType() if 'DoubleType()' in column else FloatType()).alias(column)\n",
      "\n",
      "            for column_name in columns_to_process:\n",
      "                df = df.withColumn(\n",
      "                    column_name,\n",
      "                    regexp_replace(col(column_name), \",\", \".\").cast(DoubleType() if 'DoubleType()' in column_name else FloatType())\n",
      "                )\n",
      "            \n",
      "\n",
      "Código de conversão para a tabela ft_roteiro:\n",
      "\n",
      "            from pyspark.sql.functions import col, regexp_replace\n",
      "            from pyspark.sql.types import DoubleType, FloatType\n",
      "            from pyspark.sql import DataFrame\n",
      "\n",
      "            # Substitua 'df' pelo DataFrame real\n",
      "            df = ...\n",
      "\n",
      "            columns_to_process = [\n",
      "                \n",
      "            ]\n",
      "\n",
      "            def replace_comma_with_period_and_cast(column: str) -> col:\n",
      "                return col(column).cast(DoubleType() if 'DoubleType()' in column else FloatType()).alias(column)\n",
      "\n",
      "            for column_name in columns_to_process:\n",
      "                df = df.withColumn(\n",
      "                    column_name,\n",
      "                    regexp_replace(col(column_name), \",\", \".\").cast(DoubleType() if 'DoubleType()' in column_name else FloatType())\n",
      "                )\n",
      "            \n",
      "\n",
      "Código de conversão para a tabela ft_status_day:\n",
      "\n",
      "            from pyspark.sql.functions import col, regexp_replace\n",
      "            from pyspark.sql.types import DoubleType, FloatType\n",
      "            from pyspark.sql import DataFrame\n",
      "\n",
      "            # Substitua 'df' pelo DataFrame real\n",
      "            df = ...\n",
      "\n",
      "            columns_to_process = [\n",
      "                \n",
      "            ]\n",
      "\n",
      "            def replace_comma_with_period_and_cast(column: str) -> col:\n",
      "                return col(column).cast(DoubleType() if 'DoubleType()' in column else FloatType()).alias(column)\n",
      "\n",
      "            for column_name in columns_to_process:\n",
      "                df = df.withColumn(\n",
      "                    column_name,\n",
      "                    regexp_replace(col(column_name), \",\", \".\").cast(DoubleType() if 'DoubleType()' in column_name else FloatType())\n",
      "                )\n",
      "            \n",
      "\n",
      "Código de conversão para a tabela ft_visita:\n",
      "\n",
      "            from pyspark.sql.functions import col, regexp_replace\n",
      "            from pyspark.sql.types import DoubleType, FloatType\n",
      "            from pyspark.sql import DataFrame\n",
      "\n",
      "            # Substitua 'df' pelo DataFrame real\n",
      "            df = ...\n",
      "\n",
      "            columns_to_process = [\n",
      "                \n",
      "            ]\n",
      "\n",
      "            def replace_comma_with_period_and_cast(column: str) -> col:\n",
      "                return col(column).cast(DoubleType() if 'DoubleType()' in column else FloatType()).alias(column)\n",
      "\n",
      "            for column_name in columns_to_process:\n",
      "                df = df.withColumn(\n",
      "                    column_name,\n",
      "                    regexp_replace(col(column_name), \",\", \".\").cast(DoubleType() if 'DoubleType()' in column_name else FloatType())\n",
      "                )\n",
      "            \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import csv\n",
    "\n",
    "def clean_structure(structure):\n",
    "    cleaned_structure = re.sub(r'(?<=[\\w\\d\\'\"])((?:\\s*,\\s*){2,})', ',', structure)\n",
    "    cleaned_structure = cleaned_structure.replace(\"',,\", \"',\")\n",
    "    return cleaned_structure\n",
    "\n",
    "def generate_conversion_columns(file_name):\n",
    "    with open(file_name, mode='r', encoding=\"utf-8\") as csv_file:\n",
    "        csv_reader = csv.DictReader(csv_file, delimiter=';', quotechar='\"')\n",
    "\n",
    "        queries = defaultdict(list)\n",
    "\n",
    "        for row in csv_reader:\n",
    "            table_name = row.get('Tabela', '').lower()\n",
    "            column_structure = row.get('estrutura', '').strip().replace(\"StructField('\",\"\").split(\"',\")[0]\n",
    "\n",
    "            if column_structure:\n",
    "                column_structure = clean_structure(column_structure)\n",
    "                queries[table_name].append(column_structure)\n",
    "\n",
    "        for table_name, columns in queries.items():\n",
    "         \n",
    "            float_columns = [col for col in columns if 'DoubleType()' in col or 'FloatType()' in col]\n",
    "\n",
    "            column_names = ', '.join(float_columns)\n",
    "\n",
    "            code = f\"\"\"\n",
    "            from pyspark.sql.functions import col, regexp_replace\n",
    "            from pyspark.sql.types import DoubleType, FloatType\n",
    "            from pyspark.sql import DataFrame\n",
    "\n",
    "            # Substitua 'df' pelo DataFrame real\n",
    "            df = ...\n",
    "\n",
    "            columns_to_process = [\n",
    "                {column_names}\n",
    "            ]\n",
    "\n",
    "            def replace_comma_with_period_and_cast(column: str) -> col:\n",
    "                return col(column).cast(DoubleType() if 'DoubleType()' in column else FloatType()).alias(column)\n",
    "\n",
    "            for column_name in columns_to_process:\n",
    "                df = df.withColumn(\n",
    "                    column_name,\n",
    "                    regexp_replace(col(column_name), \",\", \".\").cast(DoubleType() if 'DoubleType()' in column_name else FloatType())\n",
    "                )\n",
    "            \"\"\"\n",
    "\n",
    "            print(f\"Código de conversão para a tabela {table_name}:\\n{code}\\n\")\n",
    "\n",
    "file_name = r\"C:\\mlflowjobs\\tabelas_teste.csv\"\n",
    "providerName = \"seu_provider\"\n",
    "generate_conversion_columns(file_name)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
